#### 1.7 What about errors?

与Shor质因数分解算法同样重要的是，量子信息还有一个重要特性是**量子纠错**（quantum error correction）。只有有了这个能力，量子计算的实用化才能看到曙光。

正如之前所说，量子计算机所处理的量子信息的本质属性是系统各组成部分的非局域关联——大部分量子信息处于系统各部分的非局域关联中。如果一次只观测某个子系统，只能获得微乎其微的信息。

不幸的是，在现实中这种非局域关联非常脆弱，很容易被破坏。原因在于量子系统很难与环境（一个更大的系统）完全隔绝，一旦系统和环境相互作用产生了纠缠，我们最初在系统内部编码的量子信息就被转移到系统和环境的关联中去了。在那种情况下，我们无法仅通过观察系统本身得到有用信息。实际上，这个有用信息不可逆转地丢失了。对一个宏观系统来说，即使系统和环境相互作用很微弱，这个不可逆转移也会发生地很快。

Erwin Schrodinger曾经揶揄量子力学主流解释的拥护者，说在他们的理论中，叠加态会导致一只又死又活的猫存在，这就是那只著名的“薛定谔的猫”：$$|\text{cat}\rangle=\frac{1}{\sqrt{2}}(|\text{dead}\rangle+|\text{alive}\rangle)$$。Schrodinger认为这个态是量子力学白玉之微瑕，因为现实中从没人看到过一只半死半活的猫，只有非死即活。

过去15年量子力学理论最重要的发展之一，是我们越来越有底气来回答Schrodinger的疑惑。猫态$$|\text{cat}\rangle$$理论上可以存在，但是我们很少能见到，因为它极端不稳定。Schrodinger的这只猫从来没有真正于环境完美隔绝，因为猫不会脱离周围环境而存在（空气，地面，阳光照射过来的光子等）。假设有人制备了薛定谔猫态$$|\text{cat}\rangle$$，那么编码在$$|\text{dead}\rangle$$和$$|\text{alive}\rangle$$叠加态中的量子信息会瞬间转移到猫和环境的纠缠中消散而去，永远无法再获得。这是因为，**环境和猫的相互作用，本质上是环境不断对猫进行测量**，将猫投影到$$|\text{dead}\rangle$$或$$|\text{alive}\rangle$$中的一个本征态，这个过程叫作“**（量子）退相干**”（decoherence）。

> 译者注：为什么环境对猫测量选用的基矢一定要是$$\{|\text{dead}\rangle,|\text{alive}\rangle\}$$而不是一加一减两个叠加态？我猜想是这两个“能量”本征态的本征值相差很大造成的，即死猫和活猫的“能量”相差很大。真的是这样吗，如何定量证明？

同样道理，要执行复杂的量子计算，不可避免要搭建规模比较大的量子系统（尽管也许没有猫那么大），但同样不幸的是，这么大的量子系统不可能与环境完全隔离，因此量子系统的叠加态总会退相干，使得量子计算机失效。换句话说，**量子计算机和环境的接触（退相干）会在量子信息中引入误差**。要让量子计算机正常工作，我们必须避免或纠正这个误差。

实际上，退相干并不是我们面临的唯一问题。即使我们能把量子计算机与环境完全隔绝，也**不能保证量子计算机无误差地运行**。量子计算机执行的量子逻辑门一次只对少数qubits做幺正变换，比如这个幺正变换是$$4\times4$$的幺正矩阵，作用在2 qubits上。当然，这些幺正矩阵构成了一个连续统（continuum）。理想情况是对2 qubits做幺正变换$$U_0$$，但实际上该变换会有误差，于是真实的变换是$$U=U_0(1+O(\varepsilon))$$，即$$U$$会和$$U_0$$相差$$O(\varepsilon)$$。在做了$$O(1/\varepsilon)$$次逻辑门变换之后，这些误差将累积到无法忽略，导致计算失败。经典计算机也同样有这个**误差累积**的问题，但经典计算机处理的是离散逻辑（discrete logic），小误差并不会带来很大的问题。

对于经典计算机，现代数字电路已经足够可靠。它们通过能量耗散的形式来获得高精度的计算过程。我们可以想象一个作用在1 bit上的经典逻辑门，表现形式为处于双势阱中某一侧的小球。该逻辑门可以把小球推一下，让它越过中间的势垒跑到另一侧。当然，这个逻辑门可能不会完美运转；它也许会稍微用力过头，或者稍微用力不足。随着时间推移，这些瑕疵会逐渐累积，导致误差。

为了改进，我们在每次逻辑门作用后，对这个bit进行（等效的）降温。这是一个耗散过程，把热量耗散到环境中，同时也压缩小球的相空间，使得它接近势能的局部极小值。于是，计算过程产生的小误差最终仅仅是加热了环境，并没有牺牲计算准确度，影响计算结果。

然而我们并不能用同样地方法对量子计算机进行降温。和环境接触做降温能够提升**经典信息**的可靠性，但这么做会完全破坏**量子信息**，正所谓甲之蜜糖乙之砒霜。更广泛地来说，误差累积对于**经典可逆计算**同样是个问题。要避免误差的累积，我们必须丢弃关于误差的信息，即进行**纠错**，而扔掉信息总是个耗散过程（Landauer's principle）。

不要急，**经典纠错**已经有解决方案了。比如将1bit复制为3bit重复的值$$(0)\rightarrow(000)$$，这样即使有一位出错变为$$(100)$$，也可以通过投票机制（majority voting scheme，少数服从多数）来纠错。当然这也只能以一定概率保证不出错。假设每一个bit出错的概率为$$p$$，则两个bit出错（翻转）的情况有三种，概率为$$3p^2(1-p)$$，三个同时出错的概率为$$p^3$$，因此，投票机制失败的概率为$$3p^2(1-p)+p^3=3p^2-2p^3$$。由于不使用投票机制的话（只用1bit）出错概率为$$p$$，所以如果让纠错方案更好，必须有$$3p^2-2p^3<p$$，即$$p<1/2$$。

若要更高的正确率，只需要再多加几位重复位即可，即使用N-bit重复位（尽管这样并不是效率最高的）。假设每一个bit独立同分布，其不出错的概率都是$$P=1/2+\varepsilon$$，由中心极限定理，当位数$$N\rightarrow\infty$$时，这些bit的平均值服从宽度为$$1/\sqrt{N}$$的高斯分布，此时投票机制出错的概率为$$P_{error}\sim e^{-N\varepsilon^2}$$。因此，对任意$$\varepsilon>0$$，只要重复位足够多（冗余度$$N$$足够大），我们就可以保证任意小的出错率。即使是$$\varepsilon<0$$也不是大问题，只需要明确投票机制给出的永远是相反的答案即可。唯一有问题的是$$\varepsilon=0$$情况，此时一串$$N$$bit的字符串完全随机，无法提供有用信息。

在1950年代，John Von Neumann展示了一台具有噪声部件的经典计算机能够可靠工作，只要施加足够多的冗余度即可。他指出，如有必要，我们可以对每一个逻辑门计算许多次，然后接受主流多数的输出结果。(Von Neumann was especially interested in how his brain was able to function so well, in spite of the unreliability of neurons. He was pleased to explain why he was so smart.) 

现在我们想对量子计算机进行纠错，而**量子纠错**会面临许多困难：

- **Phase errors**. 对于量子信息，出错的地方会更多。除了bit-flip errors，即qubit错误翻转$$|0\rangle\rightarrow|1\rangle,|1\rangle\rightarrow|0\rangle$$外，还会有phase errors，即$$|0\rangle\rightarrow|0\rangle,|1\rangle\rightarrow-|1\rangle$$。这个误差是很致命的，比如它会把态$$\frac{1}{\sqrt{2}}(|0\rangle+|1\rangle)$$变成其正交态$$\frac{1}{\sqrt{2}}(|0\rangle-|1\rangle)$$。经典的编码方式并不能避免phase errors。
- **Small errors**. 量子信息是连续的，因此小扰动会把$$a|0\rangle+b|1\rangle$$的系数$$a$$和$$b$$改变小量，这些小量会随时间不断累积。相反，经典纠错纠正的是比较大的误差（bit flip）。
- **Measurement causes disturbance**. 少数服从多数投票机制中，我们需要测量每个bit来探测并纠正错误，但我们测量qubits总是会干扰它们编码的量子信息。
- **No cloning**. 经典信息可以完美拷贝，而量子信息的复制受制于不可克隆定理，不能高保真地拷贝。